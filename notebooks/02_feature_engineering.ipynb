{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1193f2f6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; margin: 30px 0;\">\n",
    "  <span style=\"\n",
    "    font-family: 'Playfair Display', serif;\n",
    "    background-color:rgb(242, 64, 10);\n",
    "    color: white;\n",
    "    font-size: 1.5em;\n",
    "    font-weight: 600;\n",
    "    font-style: italic;\n",
    "    padding: 12px 24px;\n",
    "    border-radius: 12px;\n",
    "    display: inline-block;\n",
    "    box-shadow: 0 4px 12px rgba(18, 17, 17, 0.15);\n",
    "    transition: transform 0.2s ease, box-shadow 0.2s ease;\n",
    "    cursor: default;\n",
    "  \" \n",
    "  onmouseover=\"this.style.transform='scale(1.03)'; this.style.boxShadow='0 6px 16px rgba(0,0,0,0.2)'\"\n",
    "  onmouseout=\"this.style.transform='scale(1)'; this.style.boxShadow='0 4px 12px rgba(0,0,0,0.15)'\"\n",
    "  >\n",
    "   Feature Engineering \n",
    "  </span>\n",
    "</div>\n",
    "<a id=\"import-data\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d0f779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy  as sc\n",
    "import math\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83565233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../data/cleaned_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "087474c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=['Class'])\n",
    "y_train = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cf8b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANOMALY DETECTION FEATURES\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a51bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_anomaly_detector(X_train, contamination=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Fits anomaly detection model on training data.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training data (pandas DataFrame)\n",
    "        contamination: Expected proportion of anomalies (default: 0.1)\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        dict: Fitted model and parameters\n",
    "    \"\"\"\n",
    "    numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    try:\n",
    "        iso_forest = IsolationForest(\n",
    "            contamination=contamination, \n",
    "            random_state=random_state, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        iso_forest.fit(X_train[numerical_cols])\n",
    "        \n",
    "        return {\n",
    "            'model': iso_forest,\n",
    "            'numerical_cols': numerical_cols\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Warning in anomaly detector fitting: {e}\")\n",
    "        return {\n",
    "            'model': None,\n",
    "            'numerical_cols': numerical_cols\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "651ed305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_anomaly_features(X, anomaly_model_dict):\n",
    "    \"\"\"\n",
    "    Creates anomaly detection features using fitted Isolation Forest.\n",
    "    \n",
    "    Features generated:\n",
    "    - isolation_forest_score: Anomaly score (lower = more anomalous)\n",
    "    - is_anomaly: Binary flag (1 = anomaly, 0 = normal)\n",
    "    \n",
    "    Args:\n",
    "        X: Input data (pandas DataFrame)\n",
    "        anomaly_model_dict: Dictionary from fit_anomaly_detector()\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame: Anomaly features\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    try:\n",
    "        if anomaly_model_dict['model'] is not None:\n",
    "            numerical_cols = anomaly_model_dict['numerical_cols']\n",
    "            model = anomaly_model_dict['model']\n",
    "            \n",
    "            scores = model.decision_function(X[numerical_cols])\n",
    "            predictions = model.predict(X[numerical_cols])\n",
    "            \n",
    "            features['isolation_forest_score'] = scores\n",
    "            features['is_anomaly'] = (predictions == -1).astype(int)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning in anomaly feature creation: {e}\")\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f33ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CLUSTERING FEATURES  \n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be585b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_clustering_model(X_train, n_clusters=8, random_state=42):\n",
    "    \"\"\"\n",
    "    Fits clustering model on training data.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training data (pandas DataFrame)\n",
    "        n_clusters: Number of clusters (default: 8)\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        dict: Fitted models and parameters\n",
    "    \"\"\"\n",
    "    numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_train = scaler.fit_transform(X_train[numerical_cols])\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "        kmeans.fit(scaled_train)\n",
    "        \n",
    "        return {\n",
    "            'scaler': scaler,\n",
    "            'kmeans': kmeans,\n",
    "            'numerical_cols': numerical_cols,\n",
    "            'n_clusters': n_clusters\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Warning in clustering model fitting: {e}\")\n",
    "        return {\n",
    "            'scaler': None,\n",
    "            'kmeans': None,\n",
    "            'numerical_cols': numerical_cols,\n",
    "            'n_clusters': n_clusters\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23943409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clustering_features(X, clustering_model_dict):\n",
    "    \"\"\"\n",
    "    Creates clustering-based features using fitted K-Means.\n",
    "    \n",
    "    Features generated:\n",
    "    - cluster_id: Assigned cluster ID (0 to n_clusters-1)\n",
    "    - dist_to_cluster_i: Distance to each cluster center\n",
    "    - min_cluster_distance: Distance to nearest cluster center\n",
    "    \n",
    "    Args:\n",
    "        X: Input data (pandas DataFrame)\n",
    "        clustering_model_dict: Dictionary from fit_clustering_model()\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame: Clustering features\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    try:\n",
    "        if clustering_model_dict['scaler'] is not None and clustering_model_dict['kmeans'] is not None:\n",
    "            numerical_cols = clustering_model_dict['numerical_cols']\n",
    "            scaler = clustering_model_dict['scaler']\n",
    "            kmeans = clustering_model_dict['kmeans']\n",
    "            n_clusters = clustering_model_dict['n_clusters']\n",
    "            \n",
    "            scaled_data = scaler.transform(X[numerical_cols])\n",
    "            labels = kmeans.predict(scaled_data)\n",
    "            distances = cdist(scaled_data, kmeans.cluster_centers_)\n",
    "            \n",
    "            features['cluster_id'] = labels\n",
    "            \n",
    "            for i in range(n_clusters):\n",
    "                features[f'dist_to_cluster_{i}'] = distances[:, i]\n",
    "            \n",
    "            features['min_cluster_distance'] = np.min(distances, axis=1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning in clustering feature creation: {e}\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "910e6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STATISTICAL FEATURES\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6a871c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statistical_features(X):\n",
    "    \"\"\"\n",
    "    Creates statistical features computed across numerical columns for each row.\n",
    "    \n",
    "    Features generated:\n",
    "    - row_mean: Mean value across numerical columns\n",
    "    - row_std: Standard deviation across numerical columns\n",
    "    - row_min: Minimum value across numerical columns\n",
    "    - row_max: Maximum value across numerical columns\n",
    "    - row_median: Median value across numerical columns\n",
    "    - row_cv: Coefficient of variation (std/mean)\n",
    "    - row_skew: Skewness across numerical columns\n",
    "    - row_kurtosis: Kurtosis across numerical columns\n",
    "    \n",
    "    Args:\n",
    "        X: Input data (pandas DataFrame)\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame: Statistical features\n",
    "    \"\"\"\n",
    "    numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    features = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    try:\n",
    "        data_matrix = X[numerical_cols].values\n",
    "        \n",
    "        # Basic row-wise statistics\n",
    "        features['row_mean'] = np.mean(data_matrix, axis=1)\n",
    "        features['row_std'] = np.std(data_matrix, axis=1)\n",
    "        features['row_min'] = np.min(data_matrix, axis=1)\n",
    "        features['row_max'] = np.max(data_matrix, axis=1)\n",
    "        features['row_median'] = np.median(data_matrix, axis=1)\n",
    "        \n",
    "        # Advanced statistics\n",
    "        row_means = np.mean(data_matrix, axis=1)\n",
    "        row_stds = np.std(data_matrix, axis=1)\n",
    "        features['row_cv'] = row_stds / (row_means + 1e-8)  # Coefficient of variation\n",
    "        \n",
    "        # Shape statistics\n",
    "        features['row_skew'] = stats.skew(data_matrix, axis=1)\n",
    "        features['row_kurtosis'] = stats.kurtosis(data_matrix, axis=1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning in statistical feature creation: {e}\")\n",
    "    \n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62c35fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9a22799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_features(df):\n",
    "    \"\"\"\n",
    "    Cleans feature DataFrame by handling infinite values and ensuring numeric types.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame: Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    # Replace infinite values with NaN, then fill with 0\n",
    "    df_clean = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    # Ensure all columns are numeric\n",
    "    for col in df_clean.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(df_clean[col]):\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "453a44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# COMPREHENSIVE PIPELINE FUNCTIONS\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "035af0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_all_feature_extractors(X_train, \n",
    "                              anomaly_params=None, \n",
    "                              clustering_params=None):\n",
    "    \"\"\"\n",
    "    Fits all feature extraction models on training data.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training data (pandas DataFrame)\n",
    "        anomaly_params: Parameters for anomaly detection (dict)\n",
    "        clustering_params: Parameters for clustering (dict)\n",
    "    \n",
    "    Returns:\n",
    "        dict: All fitted models and encoders\n",
    "    \"\"\"\n",
    "    # Set default parameters\n",
    "    anomaly_params = anomaly_params or {}\n",
    "    clustering_params = clustering_params or {}\n",
    "    \n",
    "    # Fit all models\n",
    "    fitted_models = {}\n",
    "    \n",
    "    # Fit anomaly detector\n",
    "    fitted_models['anomaly'] = fit_anomaly_detector(X_train, **anomaly_params)\n",
    "    \n",
    "    # Fit clustering model\n",
    "    fitted_models['clustering'] = fit_clustering_model(X_train, **clustering_params)\n",
    "    \n",
    "    return fitted_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cf76fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_with_all_features(X, fitted_models):\n",
    "    \"\"\"\n",
    "    Transforms data using all fitted feature extractors.\n",
    "    \n",
    "    Args:\n",
    "        X: Input data (pandas DataFrame)\n",
    "        fitted_models: Dictionary from fit_all_feature_extractors()\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame: Original data + all generated features\n",
    "    \"\"\"\n",
    "    # Start with original data\n",
    "    enhanced_features = X.copy()\n",
    "    \n",
    "    # Add anomaly features\n",
    "    anomaly_features = create_anomaly_features(X, fitted_models['anomaly'])\n",
    "    enhanced_features = pd.concat([enhanced_features, anomaly_features], axis=1)\n",
    "    \n",
    "    # Add clustering features\n",
    "    clustering_features = create_clustering_features(X, fitted_models['clustering'])\n",
    "    enhanced_features = pd.concat([enhanced_features, clustering_features], axis=1)\n",
    "    \n",
    "    # Add statistical features\n",
    "    statistical_features = create_statistical_features(X)\n",
    "    enhanced_features = pd.concat([enhanced_features, statistical_features], axis=1)\n",
    "    \n",
    "    # Clean features\n",
    "    enhanced_features = clean_features(enhanced_features)\n",
    "    \n",
    "    return enhanced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f4582b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fit_transform_features(X_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Convenience function to fit and transform in one step.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training data (pandas DataFrame)\n",
    "        **kwargs: Parameters for different feature extractors\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (transformed_features, fitted_models)\n",
    "    \"\"\"\n",
    "    # Fit all extractors\n",
    "    fitted_models = fit_all_feature_extractors(X_train, **kwargs)\n",
    "    \n",
    "    # Transform training data\n",
    "    transformed_features = transform_with_all_features(X_train, fitted_models)\n",
    "    \n",
    "    return transformed_features, fitted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a225b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_enhanced_dataset(df, target_column='Class', **kwargs):\n",
    "    \"\"\"\n",
    "    Complete workflow: takes full DataFrame, returns enhanced training DataFrame with target.\n",
    "    \n",
    "    Args:\n",
    "        df: Complete DataFrame with target column (pandas DataFrame)\n",
    "        target_column: Name of target column (default: 'Class')\n",
    "        **kwargs: Parameters for feature extractors\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (enhanced_train_df_with_target, fitted_models, X_test_ready_function)\n",
    "        - enhanced_train_df_with_target: Complete DataFrame with original + new features + target\n",
    "        - fitted_models: Fitted models for transforming test data\n",
    "        - transform_test_data: Function to apply same transformations to test data\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    X_train = df.drop(columns=[target_column])\n",
    "    y_train = df[target_column]\n",
    "    \n",
    "    # Fit and transform features\n",
    "    X_train_enhanced, fitted_models = fit_transform_features(X_train, **kwargs)\n",
    "    \n",
    "    # Combine enhanced features with target\n",
    "    enhanced_train_df = X_train_enhanced.copy()\n",
    "    enhanced_train_df[target_column] = y_train\n",
    "    \n",
    "    # Create function for test data transformation\n",
    "    def transform_test_data(X_test):\n",
    "        \"\"\"Transform test data using fitted models\"\"\"\n",
    "        return transform_with_all_features(X_test, fitted_models)\n",
    "    \n",
    "    return enhanced_train_df, fitted_models, transform_test_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd5e21b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: Separate fit and transform\n",
      "Original training shape: (170436, 30)\n",
      "Enhanced training shape: (170436, 50)\n",
      "Anomaly features: (170436, 2)\n",
      "Clustering features: (170436, 10)\n",
      "Statistical features: (170436, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Method 1: Separate fit and transform\")\n",
    "\n",
    "# Fit on training data\n",
    "fitted_models = fit_all_feature_extractors(X_train)\n",
    "\n",
    "# Transform training data\n",
    "X_train_enhanced = transform_with_all_features(X_train, fitted_models)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Original training shape: {X_train.shape}\")\n",
    "print(f\"Enhanced training shape: {X_train_enhanced.shape}\")\n",
    "\n",
    "anomaly_model = fit_anomaly_detector(X_train)\n",
    "clustering_model = fit_clustering_model(X_train)\n",
    "\n",
    "anomaly_features = create_anomaly_features(X_train, anomaly_model)\n",
    "clustering_features = create_clustering_features(X_train, clustering_model)\n",
    "statistical_features = create_statistical_features(X_train)\n",
    "print(f\"Anomaly features: {anomaly_features.shape}\")\n",
    "print(f\"Clustering features: {clustering_features.shape}\")\n",
    "print(f\"Statistical features: {statistical_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a30a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = pd.concat([X_train_enhanced, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b9027a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.to_csv(r\"../data/df_eda.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
